import argparse
import os
from csv import DictReader, DictWriter
from typing import Dict, Tuple


def extract_text_from_file(path: str, start: int, stop: int) -> Tuple[str, int]:
    out = open(path, "r")
    all_text = out.read()

    text_start_line = len(all_text[0:start].split('\n'))
    text_raw = all_text[start:stop]

    # Remove last \n
    text_raw = text_raw.rstrip()
    out.close()

    return text_raw, text_start_line


def extract_comments(input_path: str, project_path: str, output_path: str) -> None:
    project_map = {"hadoop": "Apache Hadoop",
                   "spark": "Apache Spark",
                   "cdt": "Eclipse",
                   "guava": "Guava",
                   "guice": "Guice",
                   "vaadin": "Vaadin"}

    header = ["Project", "Class", "Comment", "comment length", "Category Top", "Category Inner"]
    output_file = open(output_path, 'w', newline='', encoding="utf-8")
    output_csv = DictWriter(output_file, delimiter=',', fieldnames=header, extrasaction='ignore')
    output_csv.writeheader()

    input_file = open(input_path, 'r', newline='', encoding="utf-8")
    parse_new = False
    project = class_path = class_name = None
    hardcoded_string = "/home/luca/data/Comments/projects/"
    for line in input_file:
        if line[:len(hardcoded_string)] == hardcoded_string:
            project = line[len(hardcoded_string):len(hardcoded_string) + line[len(hardcoded_string):].index('/')]
            parse_new = False
            class_path = line[len(hardcoded_string):].strip()
            class_name = line[line.rindex('/') + 1:].strip()

        if parse_new:
            columns = line.strip().split(',')
            uniq = columns[0]
            start_idx = int(columns[1])
            stop_idx = int(columns[2])
            if start_idx > stop_idx:
                tmp = start_idx
                start_idx = stop_idx
                stop_idx = tmp
            category_1 = columns[3].split('->')[0].strip()
            category_2 = columns[3].split('->')[1].strip()

            java_path = os.path.join(project_path, class_path)
            comment, row_index = extract_text_from_file(java_path, start_idx, stop_idx)
            output_csv.writerow({
                "Project": project_map[project],
                "Class": class_name,
                "Comment": comment,
                "comment length": comment.count('\n') + 1,
                "Category Top": category_1,
                "Category Inner": category_2})

        if line[:4] == "uniq":
            parse_new = True
    output_file.close()


def merge_datasets(nlbse_csv: str, input_csv: str, merged_path: str) -> None:
    header = ["Project", "Class", "Comment", "comment length", "summary", "Expand", "rational", "deprecation", "usage",
              "exception", "todo", "Incomplete", "Commented code", "directive", "formatter", "License", "Ownership",
              "Pointer", "Auto generated", "Noise", "Warning", "Recommendation", "Precondition", "Coding Guidelines",
              "Extension", "Subclass explnation", "Observation", "Exapnd", "Warnings"]

    category_map = {"automatic generated by ide": "Auto generated",
                    "commentedcode": "Commented code",
                    "deprecation": "deprecation",
                    "directive": "directive",
                    "exception": "exception",
                    "expand": "Expand",
                    "formatter": "formatter",
                    "incomplete": "Incomplete",
                    "license": "License",
                    "ownership": "Ownership",
                    "pointer": "Pointer",
                    "rationale": "rational",
                    "summary": "summary",
                    "ummary": "summary",
                    "todo": "todo",
                    "turtle": "Noise",
                    "usage": "usage"}

    # Get the list of projects
    print("Parsing {}".format(nlbse_csv))
    input_file = open(nlbse_csv, 'r', newline='', encoding="utf-8")
    csv_input = DictReader(input_file, delimiter=',')
    class_list = []
    for line in csv_input:
        class_list.append(line["Project"] + "___" + line["Class"])
    input_file.close()

    merged_file = open(merged_path, 'w', newline='', encoding="utf-8")
    merged_csv = DictWriter(merged_file, delimiter=',', fieldnames=header, extrasaction='ignore')
    merged_csv.writeheader()

    input_file = open(input_csv, 'r', newline='', encoding="utf-8")
    csv_input = DictReader(input_file, delimiter=',')
    count = 0
    for line in csv_input:
        if line["Project"] + "___" + line["Class"] in class_list:
            count += 1
            print("Found: {} {} ".format(line["Project"], line["Class"]))
        else:
            merged_csv.writerow({"Project": line["Project"],
                                 "Class": line["Class"],
                                 "Comment": line["Comment"],
                                 "comment length": line["comment length"],
                                 category_map[line["Category Inner"].lower()]: line["Comment"],
                                 })
    print("Found {} occurrences".format(count))
    input_file.close()


def main(flags: Dict[str, str]) -> None:
    data_path = flags["data_path"]
    input_path = os.path.join(data_path, "JavaCommentsClassification", "List of comments",
                              "Classification_output.csv")
    projects_path = os.path.join(data_path, "JavaCommentsClassification", "projects")
    output_path = os.path.join(data_path, "output_luca.csv")
    extract_comments(input_path, projects_path, output_path)

    nlbse_csv = flags["nlbse_input"]
    merged_path = os.path.join(data_path, "merged_java.csv")
    merge_datasets(nlbse_csv, output_path, merged_path)


# Press the green button in the gutter to run the script.
if __name__ == '__main__':
    print("*** Start ***")

    parser = argparse.ArgumentParser()
    parser.add_argument("-d", "--data_path", help="Input data path", type=str, default="data")
    parser.add_argument("-nlbse", "--file_nlbse", help="First CSV file (NLBSE", type=str,
                        default="java_combined.csv")
    args = parser.parse_args()

    # Check for user's flags

    # Get data path
    if args.data_path is None or not os.path.exists(args.data_path) or not os.path.isdir(args.data_path):
        print("Invalid --data_path argument: {}".format(args.data_path))
        exit(-1)
    abs_data_path = os.path.abspath(args.data_path)

    if args.file_nlbse is None:
        print("Invalid --file_nlbse argument: {}".format(args.file_nlbse))
        exit(-1)

    abs_nlbse_input = os.path.join(abs_data_path, args.file_nlbse)
    if not os.path.exists(abs_nlbse_input) or os.path.isdir(abs_nlbse_input):
        print("Invalid input file: {}".format(abs_nlbse_input))
        exit(-1)

    option_flags = {
        'data_path': abs_data_path,
        'nlbse_input': abs_nlbse_input
    }

    main(option_flags)
